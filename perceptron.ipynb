{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Introdução ao modelo de Perceptron\n",
        "\n",
        "O modelo de algoritmo Perceptron é um modelo de rede neural utilizado para classificação binária, indicando se um elemento pertence ou não a uma determinada classe. Trata-se de um modelo de aprendizado supervisionado.\n",
        "\n",
        "O Perceptron pode receber n parâmetros de entrada, onde cada entrada possui um peso associado. Esses pesos são ajustados durante o treinamento com base em uma função de erro, de modo a minimizar a diferença entre a saída prevista e a saída esperada."
      ],
      "metadata": {
        "id": "9kPGYu_48LoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um Perceptron de n entrada pode ter sua fronteira de decisão definida por:\n",
        "\n",
        "\n",
        "$u = x_1 w_1 + x_2 w_2 + \\cdots + x_n w_n + b$"
      ],
      "metadata": {
        "id": "vXbb6nVW_BL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Onde na equação:\n",
        "* $u$ é o valor intermediário antes da ativação.\n",
        "* $wi$ são os pesos.\n",
        "* $xi$ são as entradas.\n",
        "* $b$ é o bias (viés).\n",
        "\n"
      ],
      "metadata": {
        "id": "ID8Iz5OIACsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como $xi$ é a entrada, e $wi$ seus pesos, logo o seu produto será $xiwi$. A soma ponderada será $Σxiwi$.\n"
      ],
      "metadata": {
        "id": "YFchrZyUBA5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A implementação, antes da função de ativação, pode ser descrita abaixo:"
      ],
      "metadata": {
        "id": "bMTWlalFGnB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Peceptron com u antes da função de ativação\n",
        "#entradas binárias\n",
        "x_n = [1, -1]\n",
        "w_n = [0.6, 0.4]\n",
        "b = -0.2\n",
        "\n",
        "#Inicializar o u\n",
        "u = 0\n",
        "\n",
        "#Soma ponderada\n",
        "for i in range(len(x_n)):\n",
        "    u += x_n[i] * w_n[i]\n",
        "\n",
        "#Adição do bias\n",
        "u += b\n",
        "\n",
        "u\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCABL7ufGfaz",
        "outputId": "ba365312-1137-4f87-9684-47e8c890037f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.551115123125783e-17"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O valor de u é então passado como entrada para a função de ativação ϕ($u$). A função de ativação  seráuma função onde vai transformar $u$,  que é uma combinação linear, em uma saída binária.\n",
        "A função de ativação a ser utilizada será uma função degrau, mostrada abaixo"
      ],
      "metadata": {
        "id": "8L7zxgB-GjEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ϕ($u$) =\\begin{cases}\n",
        "1 & \\text{se } u \\geq 0 \\\\\n",
        "0 & \\text{se } u < 0\n",
        "\\end{cases}"
      ],
      "metadata": {
        "id": "utIecO8pITQb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWQpRp2WGlRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}